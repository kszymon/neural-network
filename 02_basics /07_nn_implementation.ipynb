{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXg6XCXtOmEORKV83iRmNN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kszymon/neural-network/blob/main/02_basics%20/07_nn_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementacja prostej sieci neuronowej\n",
        "\n",
        "##### Kroki:\n",
        "    1. Zainicjowanie parametrów sieci\n",
        "    2. Propagacja wprzód\n",
        "    3. Obliczenie błędu predykcji\n",
        "    4. Propagacja wsteczna (uczenie modelu)\n",
        "    5. Test działania modelu"
      ],
      "metadata": {
        "id": "gAhzRXvryTj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "X = np.array([1.4, 0.7])\n",
        "y_true = np.array([1.8])"
      ],
      "metadata": {
        "id": "pDVA2T0HUIPi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    W1 = np.random.rand(n_h, n_x)\n",
        "    W2 = np.random.rand(n_h, n_y)\n",
        "    return W1, W2"
      ],
      "metadata": {
        "id": "O6mVKkyIG5AA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, W1, W2):\n",
        "    H1 = np.dot(X, W1)\n",
        "    y_pred = np.dot(H1, W2)\n",
        "    return H1, y_pred"
      ],
      "metadata": {
        "id": "_pDAaH6_HO02"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error(y_pred, y_true):\n",
        "    return y_pred - y_true"
      ],
      "metadata": {
        "id": "-ubN97lQHdXv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W1, W2):\n",
        "    _, y_pred = forward_propagation(X, W1, W2)\n",
        "    return y_pred[0]"
      ],
      "metadata": {
        "id": "2mafcfNHHsye"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, W1, W2, learning_rate, iters=1000, precision=0.0000001):\n",
        "\n",
        "    H1, y_pred = forward_propagation(X, W1, W2)\n",
        "    train_loss = []\n",
        "\n",
        "    for i in range(iters):\n",
        "        error = calculate_error(y_pred, y_true)\n",
        "        W2 = W2 - learning_rate * error * H1.T\n",
        "        W1 = W1 - learning_rate * error * np.dot(X.T, W2.T)\n",
        "\n",
        "        y_pred = predict(X, W1, W2)\n",
        "        print(f'Iter #{i}: y_pred {y_pred}: loss: {abs(calculate_error(y_pred, y_true[0]))}')\n",
        "        train_loss.append(abs(calculate_error(y_pred, y_true[0])))\n",
        "\n",
        "        if abs(error) < precision:\n",
        "            break\n",
        "\n",
        "    return W1, W2, train_loss"
      ],
      "metadata": {
        "id": "l7QJyWuJJFWi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "    W1, W2 = initialize_parameters(2, 2, 1)\n",
        "\n",
        "    W1, W2, train_loss = backpropagation(X, W1, W2, 0.01)\n",
        "\n",
        "    model = {'W1': W1, 'W2': W2, 'train_loss': train_loss}\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "6xbpQKlLLASl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29D0Be1aLpSp",
        "outputId": "186208c4-1d12-4439-a567-4930180927c8",
        "collapsed": true
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter #0: y_pred 0.47775082418068876: loss: 1.3222491758193113\n",
            "Iter #1: y_pred 0.5203197164995874: loss: 1.2796802835004126\n",
            "Iter #2: y_pred 0.5624603087798719: loss: 1.2375396912201282\n",
            "Iter #3: y_pred 0.6041630898849911: loss: 1.195836910115009\n",
            "Iter #4: y_pred 0.6454096471221384: loss: 1.1545903528778616\n",
            "Iter #5: y_pred 0.686174266816854: loss: 1.113825733183146\n",
            "Iter #6: y_pred 0.7264254411736586: loss: 1.0735745588263415\n",
            "Iter #7: y_pred 0.7661272789328608: loss: 1.0338727210671392\n",
            "Iter #8: y_pred 0.8052408159236343: loss: 0.9947591840763658\n",
            "Iter #9: y_pred 0.8437252210745323: loss: 0.9562747789254677\n",
            "Iter #10: y_pred 0.8815388936200005: loss: 0.9184611063799996\n",
            "Iter #11: y_pred 0.9186404479839603: loss: 0.8813595520160398\n",
            "Iter #12: y_pred 0.9549895839833127: loss: 0.8450104160166874\n",
            "Iter #13: y_pred 0.9905478414374655: loss: 0.8094521585625345\n",
            "Iter #14: y_pred 1.025279239868215: loss: 0.7747207601317851\n",
            "Iter #15: y_pred 1.0591508056150682: loss: 0.7408491943849318\n",
            "Iter #16: y_pred 1.0921329902786125: loss: 0.7078670097213875\n",
            "Iter #17: y_pred 1.1241999858610763: loss: 0.6758000141389238\n",
            "Iter #18: y_pred 1.1553299432399835: loss: 0.6446700567600165\n",
            "Iter #19: y_pred 1.185505101647381: loss: 0.6144948983526191\n",
            "Iter #20: y_pred 1.2147118376107076: loss: 0.5852881623892925\n",
            "Iter #21: y_pred 1.2429406423347058: loss: 0.5570593576652942\n",
            "Iter #22: y_pred 1.2701860367729518: loss: 0.5298139632270482\n",
            "Iter #23: y_pred 1.296446433669521: loss: 0.5035535663304791\n",
            "Iter #24: y_pred 1.3217239556708602: loss: 0.47827604432913984\n",
            "Iter #25: y_pred 1.346024218245523: loss: 0.45397578175447695\n",
            "Iter #26: y_pred 1.3693560856383367: loss: 0.4306439143616634\n",
            "Iter #27: y_pred 1.3917314074600646: loss: 0.4082685925399354\n",
            "Iter #28: y_pred 1.4131647428070897: loss: 0.38683525719291034\n",
            "Iter #29: y_pred 1.4336730780491806: loss: 0.3663269219508194\n",
            "Iter #30: y_pred 1.4532755436450078: loss: 0.34672445635499227\n",
            "Iter #31: y_pred 1.4719931345688555: loss: 0.32800686543114455\n",
            "Iter #32: y_pred 1.489848438177975: loss: 0.31015156182202497\n",
            "Iter #33: y_pred 1.5068653726340866: loss: 0.29313462736591345\n",
            "Iter #34: y_pred 1.5230689383266065: loss: 0.27693106167339354\n",
            "Iter #35: y_pred 1.5384849841373773: loss: 0.2615150158626227\n",
            "Iter #36: y_pred 1.5531399898420248: loss: 0.2468600101579752\n",
            "Iter #37: y_pred 1.567060865463699: loss: 0.232939134536301\n",
            "Iter #38: y_pred 1.5802747679806677: loss: 0.21972523201933236\n",
            "Iter #39: y_pred 1.5928089354380996: loss: 0.2071910645619004\n",
            "Iter #40: y_pred 1.6046905382229744: loss: 0.19530946177702568\n",
            "Iter #41: y_pred 1.6159465470249987: loss: 0.1840534529750013\n",
            "Iter #42: y_pred 1.6266036168207822: loss: 0.1733963831792178\n",
            "Iter #43: y_pred 1.63668798607784: loss: 0.16331201392216\n",
            "Iter #44: y_pred 1.6462253902739443: loss: 0.15377460972605572\n",
            "Iter #45: y_pred 1.6552409887604627: loss: 0.14475901123953738\n",
            "Iter #46: y_pred 1.6637593039605378: loss: 0.1362406960394622\n",
            "Iter #47: y_pred 1.6718041718794512: loss: 0.12819582812054886\n",
            "Iter #48: y_pred 1.6793987029108668: loss: 0.12060129708913325\n",
            "Iter #49: y_pred 1.6865652519449181: loss: 0.11343474805508191\n",
            "Iter #50: y_pred 1.6933253968187492: loss: 0.10667460318125088\n",
            "Iter #51: y_pred 1.6996999241940762: loss: 0.10030007580592382\n",
            "Iter #52: y_pred 1.7057088219969534: loss: 0.09429117800304665\n",
            "Iter #53: y_pred 1.7113712776099892: loss: 0.08862872239001085\n",
            "Iter #54: y_pred 1.7167056810648456: loss: 0.08329431893515449\n",
            "Iter #55: y_pred 1.7217296325414804: loss: 0.07827036745851967\n",
            "Iter #56: y_pred 1.7264599535389993: loss: 0.07354004646100076\n",
            "Iter #57: y_pred 1.7309127011401986: loss: 0.06908729885980147\n",
            "Iter #58: y_pred 1.7351031848471579: loss: 0.06489681515284218\n",
            "Iter #59: y_pred 1.7390459855180398: loss: 0.06095401448196025\n",
            "Iter #60: y_pred 1.7427549759851644: loss: 0.057245024014835666\n",
            "Iter #61: y_pred 1.7462433429812245: loss: 0.05375665701877552\n",
            "Iter #62: y_pred 1.7495236100440095: loss: 0.050476389955990575\n",
            "Iter #63: y_pred 1.7526076611102193: loss: 0.04739233888978078\n",
            "Iter #64: y_pred 1.7555067645458284: loss: 0.04449323545417161\n",
            "Iter #65: y_pred 1.7582315973941327: loss: 0.04176840260586734\n",
            "Iter #66: y_pred 1.7607922696531622: loss: 0.03920773034683789\n",
            "Iter #67: y_pred 1.7631983484217237: loss: 0.036801651578276307\n",
            "Iter #68: y_pred 1.7654588817781245: loss: 0.034541118221875555\n",
            "Iter #69: y_pred 1.7675824222777847: loss: 0.03241757772221532\n",
            "Iter #70: y_pred 1.7695770499756733: loss: 0.03042295002432671\n",
            "Iter #71: y_pred 1.771450394896963: loss: 0.028549605103036946\n",
            "Iter #72: y_pred 1.7732096588947255: loss: 0.026790341105274562\n",
            "Iter #73: y_pred 1.774861636846979: loss: 0.025138363153021093\n",
            "Iter #74: y_pred 1.7764127371572318: loss: 0.023587262842768242\n",
            "Iter #75: y_pred 1.7778690015329075: loss: 0.022130998467092544\n",
            "Iter #76: y_pred 1.7792361240248984: loss: 0.020763875975101653\n",
            "Iter #77: y_pred 1.7805194693191018: loss: 0.019480530680898278\n",
            "Iter #78: y_pred 1.7817240902772846: loss: 0.018275909722715422\n",
            "Iter #79: y_pred 1.7828547447301206: loss: 0.017145255269879422\n",
            "Iter #80: y_pred 1.7839159115298464: loss: 0.016084088470153635\n",
            "Iter #81: y_pred 1.784911805873826: loss: 0.015088194126174015\n",
            "Iter #82: y_pred 1.785846393913453: loss: 0.014153606086547033\n",
            "Iter #83: y_pred 1.7867234066653805: loss: 0.013276593334619502\n",
            "Iter #84: y_pred 1.7875463532440663: loss: 0.012453646755933745\n",
            "Iter #85: y_pred 1.7883185334362186: loss: 0.01168146656378144\n",
            "Iter #86: y_pred 1.7890430496388665: loss: 0.010956950361133533\n",
            "Iter #87: y_pred 1.7897228181836415: loss: 0.010277181816358505\n",
            "Iter #88: y_pred 1.7903605800703621: loss: 0.009639419929637905\n",
            "Iter #89: y_pred 1.7909589111333402: loss: 0.009041088866659885\n",
            "Iter #90: y_pred 1.7915202316638739: loss: 0.008479768336126181\n",
            "Iter #91: y_pred 1.7920468155123246: loss: 0.007953184487675458\n",
            "Iter #92: y_pred 1.7925407986929023: loss: 0.0074592013070977625\n",
            "Iter #93: y_pred 1.7930041875139482: loss: 0.006995812486051856\n",
            "Iter #94: y_pred 1.79343886625601: loss: 0.006561133743990144\n",
            "Iter #95: y_pred 1.7938466044194779: loss: 0.006153395580522192\n",
            "Iter #96: y_pred 1.7942290635629394: loss: 0.005770936437060614\n",
            "Iter #97: y_pred 1.7945878037527445: loss: 0.00541219624725553\n",
            "Iter #98: y_pred 1.7949242896435964: loss: 0.00507571035640364\n",
            "Iter #99: y_pred 1.7952398962092577: loss: 0.0047601037907423205\n",
            "Iter #100: y_pred 1.7955359141417324: loss: 0.00446408585826763\n",
            "Iter #101: y_pred 1.795813554936549: loss: 0.004186445063451005\n",
            "Iter #102: y_pred 1.7960739556810235: loss: 0.003926044318976585\n",
            "Iter #103: y_pred 1.7963181835616495: loss: 0.003681816438350527\n",
            "Iter #104: y_pred 1.7965472401060394: loss: 0.003452759893960655\n",
            "Iter #105: y_pred 1.796762065174116: loss: 0.00323793482588397\n",
            "Iter #106: y_pred 1.7969635407125617: loss: 0.0030364592874383423\n",
            "Iter #107: y_pred 1.7971524942858603: loss: 0.0028475057141397198\n",
            "Iter #108: y_pred 1.7973297023965797: loss: 0.002670297603420302\n",
            "Iter #109: y_pred 1.7974958936069383: loss: 0.0025041063930617558\n",
            "Iter #110: y_pred 1.7976517514730472: loss: 0.002348248526952812\n",
            "Iter #111: y_pred 1.7977979173026548: loss: 0.002202082697345231\n",
            "Iter #112: y_pred 1.7979349927466213: loss: 0.00206500725337877\n",
            "Iter #113: y_pred 1.7980635422338285: loss: 0.0019364577661715732\n",
            "Iter #114: y_pred 1.798184095258689: loss: 0.001815904741311103\n",
            "Iter #115: y_pred 1.7982971485299188: loss: 0.0017028514700812014\n",
            "Iter #116: y_pred 1.7984031679887722: loss: 0.0015968320112278445\n",
            "Iter #117: y_pred 1.798502590704461: loss: 0.0014974092955390983\n",
            "Iter #118: y_pred 1.7985958266540703: loss: 0.0014041733459297934\n",
            "Iter #119: y_pred 1.7986832603938423: loss: 0.0013167396061577463\n",
            "Iter #120: y_pred 1.7987652526283422: loss: 0.0012347473716578516\n",
            "Iter #121: y_pred 1.7988421416836093: loss: 0.001157858316390703\n",
            "Iter #122: y_pred 1.7989142448900772: loss: 0.0010857551099228147\n",
            "Iter #123: y_pred 1.7989818598806964: loss: 0.0010181401193036788\n",
            "Iter #124: y_pred 1.7990452658093747: loss: 0.000954734190625306\n",
            "Iter #125: y_pred 1.7991047244945615: loss: 0.000895275505438553\n",
            "Iter #126: y_pred 1.799160481492506: loss: 0.0008395185074940859\n",
            "Iter #127: y_pred 1.7992127671044686: loss: 0.0007872328955313979\n",
            "Iter #128: y_pred 1.7992617973218947: loss: 0.0007382026781053153\n",
            "Iter #129: y_pred 1.799307774713335: loss: 0.0006922252866650158\n",
            "Iter #130: y_pred 1.799350889256658: loss: 0.0006491107433419518\n",
            "Iter #131: y_pred 1.7993913191199102: loss: 0.0006086808800898069\n",
            "Iter #132: y_pred 1.7994292313939488: loss: 0.0005707686060512085\n",
            "Iter #133: y_pred 1.7994647827798116: loss: 0.0005352172201884553\n",
            "Iter #134: y_pred 1.7994981202335922: loss: 0.000501879766407809\n",
            "Iter #135: y_pred 1.799529381571432: loss: 0.00047061842856810365\n",
            "Iter #136: y_pred 1.799558696037076: loss: 0.0004413039629240778\n",
            "Iter #137: y_pred 1.7995861848342956: loss: 0.00041381516570448973\n",
            "Iter #138: y_pred 1.7996119616263373: loss: 0.00038803837366274685\n",
            "Iter #139: y_pred 1.7996361330044326: loss: 0.0003638669955674523\n",
            "Iter #140: y_pred 1.7996587989272692: loss: 0.00034120107273083455\n",
            "Iter #141: y_pred 1.7996800531332222: loss: 0.0003199468667778316\n",
            "Iter #142: y_pred 1.799699983527016: loss: 0.00030001647298405487\n",
            "Iter #143: y_pred 1.7997186725424064: loss: 0.00028132745759368305\n",
            "Iter #144: y_pred 1.799736197482355: loss: 0.00026380251764512863\n",
            "Iter #145: y_pred 1.7997526308380936: loss: 0.0002473691619064855\n",
            "Iter #146: y_pred 1.7997680405883811: loss: 0.00023195941161890943\n",
            "Iter #147: y_pred 1.799782490480178: loss: 0.00021750951982202338\n",
            "Iter #148: y_pred 1.7997960402918907: loss: 0.00020395970810938024\n",
            "Iter #149: y_pred 1.7998087460802608: loss: 0.00019125391973928707\n",
            "Iter #150: y_pred 1.799820660411923: loss: 0.00017933958807714312\n",
            "Iter #151: y_pred 1.7998318325805622: loss: 0.00016816741943781466\n",
            "Iter #152: y_pred 1.7998423088105868: loss: 0.0001576911894132227\n",
            "Iter #153: y_pred 1.7998521324481316: loss: 0.00014786755186846356\n",
            "Iter #154: y_pred 1.7998613441401952: loss: 0.0001386558598048815\n",
            "Iter #155: y_pred 1.7998699820026307: loss: 0.00013001799736933606\n",
            "Iter #156: y_pred 1.7998780817776976: loss: 0.00012191822230245286\n",
            "Iter #157: y_pred 1.7998856769818121: loss: 0.0001143230181879229\n",
            "Iter #158: y_pred 1.799892799044106: loss: 0.00010720095589400458\n",
            "Iter #159: y_pred 1.799899477436369: loss: 0.00010052256363102252\n",
            "Iter #160: y_pred 1.7999057397949083: loss: 9.426020509173405e-05\n",
            "Iter #161: y_pred 1.7999116120348222: loss: 8.838796517784964e-05\n",
            "Iter #162: y_pred 1.7999171184571692: loss: 8.288154283087046e-05\n",
            "Iter #163: y_pred 1.799922281849463: loss: 7.77181505371427e-05\n",
            "Iter #164: y_pred 1.7999271235799168: loss: 7.287642008324546e-05\n",
            "Iter #165: y_pred 1.7999316636858218: loss: 6.833631417824115e-05\n",
            "Iter #166: y_pred 1.7999359209564247: loss: 6.40790435753047e-05\n",
            "Iter #167: y_pred 1.7999399130106464: loss: 6.0086989353669296e-05\n",
            "Iter #168: y_pred 1.7999436563699636: loss: 5.6343630036481684e-05\n",
            "Iter #169: y_pred 1.7999471665267532: loss: 5.2833473246804985e-05\n",
            "Iter #170: y_pred 1.7999504580083818: loss: 4.954199161821826e-05\n",
            "Iter #171: y_pred 1.7999535444373063: loss: 4.645556269378126e-05\n",
            "Iter #172: y_pred 1.7999564385874307: loss: 4.356141256933732e-05\n",
            "Iter #173: y_pred 1.7999591524369567: loss: 4.084756304334469e-05\n",
            "Iter #174: y_pred 1.7999616972179413: loss: 3.830278205874116e-05\n",
            "Iter #175: y_pred 1.7999640834627697: loss: 3.5916537230340495e-05\n",
            "Iter #176: y_pred 1.7999663210477341: loss: 3.367895226591422e-05\n",
            "Iter #177: y_pred 1.7999684192338994: loss: 3.158076610065841e-05\n",
            "Iter #178: y_pred 1.7999703867054242: loss: 2.9613294575847604e-05\n",
            "Iter #179: y_pred 1.7999722316054934: loss: 2.7768394506688665e-05\n",
            "Iter #180: y_pred 1.7999739615700154: loss: 2.603842998460948e-05\n",
            "Iter #181: y_pred 1.7999755837592204: loss: 2.4416240779645548e-05\n",
            "Iter #182: y_pred 1.7999771048872897: loss: 2.289511271036382e-05\n",
            "Iter #183: y_pred 1.7999785312501402: loss: 2.1468749859865355e-05\n",
            "Iter #184: y_pred 1.7999798687514794: loss: 2.013124852062731e-05\n",
            "Iter #185: y_pred 1.7999811229272353: loss: 1.88770727647114e-05\n",
            "Iter #186: y_pred 1.799982298968469: loss: 1.7701031530981126e-05\n",
            "Iter #187: y_pred 1.7999834017428533: loss: 1.6598257146727136e-05\n",
            "Iter #188: y_pred 1.7999844358148207: loss: 1.5564185179339773e-05\n",
            "Iter #189: y_pred 1.7999854054644528: loss: 1.4594535547196585e-05\n",
            "Iter #190: y_pred 1.799986314705194: loss: 1.368529480605396e-05\n",
            "Iter #191: y_pred 1.799987167300459: loss: 1.283269954099886e-05\n",
            "Iter #192: y_pred 1.799987966779212: loss: 1.2033220788021382e-05\n",
            "Iter #193: y_pred 1.799988716450569: loss: 1.1283549431029272e-05\n",
            "Iter #194: y_pred 1.7999894194174964: loss: 1.0580582503694203e-05\n",
            "Iter #195: y_pred 1.7999900785896479: loss: 9.921410352164983e-06\n",
            "Iter #196: y_pred 1.7999906966954144: loss: 9.303304585595029e-06\n",
            "Iter #197: y_pred 1.79999127629321: loss: 8.723706790059182e-06\n",
            "Iter #198: y_pred 1.799991819782063: loss: 8.180217937026057e-06\n",
            "Iter #199: y_pred 1.799992329411547: loss: 7.670588453079219e-06\n",
            "Iter #200: y_pred 1.7999928072910878: loss: 7.192708912251433e-06\n",
            "Iter #201: y_pred 1.7999932553986981: loss: 6.744601301900133e-06\n",
            "Iter #202: y_pred 1.799993675589161: loss: 6.324410839031458e-06\n",
            "Iter #203: y_pred 1.799994069601709: loss: 5.93039829110964e-06\n",
            "Iter #204: y_pred 1.799994439067222: loss: 5.560932778037042e-06\n",
            "Iter #205: y_pred 1.7999947855149756: loss: 5.214485024440663e-06\n",
            "Iter #206: y_pred 1.7999951103789753: loss: 4.889621024739554e-06\n",
            "Iter #207: y_pred 1.7999954150038868: loss: 4.584996113221607e-06\n",
            "Iter #208: y_pred 1.799995700650605: loss: 4.2993493949428085e-06\n",
            "Iter #209: y_pred 1.799995968501471: loss: 4.0314985290113015e-06\n",
            "Iter #210: y_pred 1.7999962196651662: loss: 3.7803348338361076e-06\n",
            "Iter #211: y_pred 1.7999964551813026: loss: 3.5448186974651463e-06\n",
            "Iter #212: y_pred 1.7999966760247244: loss: 3.3239752756930585e-06\n",
            "Iter #213: y_pred 1.799996883109542: loss: 3.116890457954824e-06\n",
            "Iter #214: y_pred 1.7999970772929192: loss: 2.922707080799114e-06\n",
            "Iter #215: y_pred 1.7999972593786162: loss: 2.740621383834352e-06\n",
            "Iter #216: y_pred 1.7999974301203214: loss: 2.5698796786155498e-06\n",
            "Iter #217: y_pred 1.799997590224767: loss: 2.4097752331364575e-06\n",
            "Iter #218: y_pred 1.799997740354656: loss: 2.2596453439494013e-06\n",
            "Iter #219: y_pred 1.7999978811314055: loss: 2.1188685945805474e-06\n",
            "Iter #220: y_pred 1.7999980131377178: loss: 1.9868622822549753e-06\n",
            "Iter #221: y_pred 1.7999981369199936: loss: 1.8630800064922681e-06\n",
            "Iter #222: y_pred 1.799998252990592: loss: 1.747009408026301e-06\n",
            "Iter #223: y_pred 1.799998361829952: loss: 1.6381700480572192e-06\n",
            "Iter #224: y_pred 1.7999984638885822: loss: 1.5361114178435997e-06\n",
            "Iter #225: y_pred 1.7999985595889243: loss: 1.4404110757482158e-06\n",
            "Iter #226: y_pred 1.799998649327101: loss: 1.3506728990808625e-06\n",
            "Iter #227: y_pred 1.7999987334745566: loss: 1.2665254434107709e-06\n",
            "Iter #228: y_pred 1.7999988123795947: loss: 1.187620405351808e-06\n",
            "Iter #229: y_pred 1.79999888636882: loss: 1.1136311799386789e-06\n",
            "Iter #230: y_pred 1.7999989557484894: loss: 1.0442515105957284e-06\n",
            "Iter #231: y_pred 1.799999020805779: loss: 9.791942210402027e-07\n",
            "Iter #232: y_pred 1.7999990818099745: loss: 9.181900255672559e-07\n",
            "Iter #233: y_pred 1.7999991390135857: loss: 8.609864143860335e-07\n",
            "Iter #234: y_pred 1.7999991926533894: loss: 8.073466106761629e-07\n",
            "Iter #235: y_pred 1.799999242951413: loss: 7.570485871521981e-07\n",
            "Iter #236: y_pred 1.7999992901158497: loss: 7.098841503516695e-07\n",
            "Iter #237: y_pred 1.7999993343419238: loss: 6.656580762154363e-07\n",
            "Iter #238: y_pred 1.7999993758126962: loss: 6.241873038437262e-07\n",
            "Iter #239: y_pred 1.7999994146998226: loss: 5.853001774358546e-07\n",
            "Iter #240: y_pred 1.7999994511642656: loss: 5.488357344152206e-07\n",
            "Iter #241: y_pred 1.7999994853569592: loss: 5.146430408498048e-07\n",
            "Iter #242: y_pred 1.799999517419434: loss: 4.825805659525173e-07\n",
            "Iter #243: y_pred 1.7999995474844042: loss: 4.5251559588344037e-07\n",
            "Iter #244: y_pred 1.7999995756763145: loss: 4.243236855216992e-07\n",
            "Iter #245: y_pred 1.7999996021118574: loss: 3.978881426558445e-07\n",
            "Iter #246: y_pred 1.7999996269004548: loss: 3.7309954525888145e-07\n",
            "Iter #247: y_pred 1.7999996501447126: loss: 3.4985528740705263e-07\n",
            "Iter #248: y_pred 1.7999996719408435: loss: 3.280591565069102e-07\n",
            "Iter #249: y_pred 1.7999996923790667: loss: 3.0762093339298247e-07\n",
            "Iter #250: y_pred 1.7999997115439799: loss: 2.88456020181016e-07\n",
            "Iter #251: y_pred 1.7999997295149113: loss: 2.704850887713661e-07\n",
            "Iter #252: y_pred 1.7999997463662463: loss: 2.536337537772937e-07\n",
            "Iter #253: y_pred 1.7999997621677362: loss: 2.378322638829644e-07\n",
            "Iter #254: y_pred 1.7999997769847864: loss: 2.2301521362955157e-07\n",
            "Iter #255: y_pred 1.7999997908787284: loss: 2.091212716326396e-07\n",
            "Iter #256: y_pred 1.7999998039070721: loss: 1.9609292789546373e-07\n",
            "Iter #257: y_pred 1.7999998161237443: loss: 1.8387625577709343e-07\n",
            "Iter #258: y_pred 1.7999998275793128: loss: 1.724206872832923e-07\n",
            "Iter #259: y_pred 1.7999998383211948: loss: 1.6167880523276779e-07\n",
            "Iter #260: y_pred 1.7999998483938526: loss: 1.5160614741382972e-07\n",
            "Iter #261: y_pred 1.7999998578389798: loss: 1.421610202889667e-07\n",
            "Iter #262: y_pred 1.7999998666956718: loss: 1.33304328242545e-07\n",
            "Iter #263: y_pred 1.7999998750005881: loss: 1.249994119323361e-07\n",
            "Iter #264: y_pred 1.7999998827881043: loss: 1.1721189574487312e-07\n",
            "Iter #265: y_pred 1.7999998900904552: loss: 1.0990954479872528e-07\n",
            "Iter #266: y_pred 1.7999998969378668: loss: 1.0306213327204716e-07\n",
            "Iter #267: y_pred 1.7999999033586818: loss: 9.664131828124312e-08\n",
            "Iter #268: y_pred 1.7999999093794767: loss: 9.062052330754966e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = pd.DataFrame({'train_loss': model['train_loss']})\n",
        "loss = loss.reset_index().rename(columns={'index': 'iter'})\n",
        "loss['iter'] +=1\n",
        "loss.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3S6wCN0BM7x7",
        "outputId": "b1c2212d-b063-459c-d852-3c9cc64a65bc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   iter  train_loss\n",
              "0     1    1.322249\n",
              "1     2    1.279680\n",
              "2     3    1.237540\n",
              "3     4    1.195837\n",
              "4     5    1.154590"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c2ac9b0-93b9-4f9e-8a66-f929fb1ec3f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iter</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.322249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.279680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.237540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.195837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.154590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c2ac9b0-93b9-4f9e-8a66-f929fb1ec3f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c2ac9b0-93b9-4f9e-8a66-f929fb1ec3f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c2ac9b0-93b9-4f9e-8a66-f929fb1ec3f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01f3835b-2cee-47de-b206-b8311a0c8732\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01f3835b-2cee-47de-b206-b8311a0c8732')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01f3835b-2cee-47de-b206-b8311a0c8732 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "loss",
              "summary": "{\n  \"name\": \"loss\",\n  \"rows\": 269,\n  \"fields\": [\n    {\n      \"column\": \"iter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77,\n        \"min\": 1,\n        \"max\": 269,\n        \"num_unique_values\": 269,\n        \"samples\": [\n          31,\n          117,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2663874148905844,\n        \"min\": 9.062052330754966e-08,\n        \"max\": 1.3222491758193113,\n        \"num_unique_values\": 269,\n        \"samples\": [\n          0.34672445635499227,\n          0.0015968320112278445,\n          0.017145255269879422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data=go.Scatter(x=loss['iter'], y=loss['train_loss'], mode='markers+lines'))\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "pnx4mUPZNNJo",
        "outputId": "a52e2a9b-7c15-4d08-f8c8-38bb9a6e8d00"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"71f5d74c-6c09-42f1-bf07-954fc2cce2f5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"71f5d74c-6c09-42f1-bf07-954fc2cce2f5\")) {                    Plotly.newPlot(                        \"71f5d74c-6c09-42f1-bf07-954fc2cce2f5\",                        [{\"mode\":\"markers+lines\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269],\"y\":[1.3222491758193113,1.2796802835004126,1.2375396912201282,1.195836910115009,1.1545903528778616,1.113825733183146,1.0735745588263415,1.0338727210671392,0.9947591840763658,0.9562747789254677,0.9184611063799996,0.8813595520160398,0.8450104160166874,0.8094521585625345,0.7747207601317851,0.7408491943849318,0.7078670097213875,0.6758000141389238,0.6446700567600165,0.6144948983526191,0.5852881623892925,0.5570593576652942,0.5298139632270482,0.5035535663304791,0.47827604432913984,0.45397578175447695,0.4306439143616634,0.4082685925399354,0.38683525719291034,0.3663269219508194,0.34672445635499227,0.32800686543114455,0.31015156182202497,0.29313462736591345,0.27693106167339354,0.2615150158626227,0.2468600101579752,0.232939134536301,0.21972523201933236,0.2071910645619004,0.19530946177702568,0.1840534529750013,0.1733963831792178,0.16331201392216,0.15377460972605572,0.14475901123953738,0.1362406960394622,0.12819582812054886,0.12060129708913325,0.11343474805508191,0.10667460318125088,0.10030007580592382,0.09429117800304665,0.08862872239001085,0.08329431893515449,0.07827036745851967,0.07354004646100076,0.06908729885980147,0.06489681515284218,0.06095401448196025,0.057245024014835666,0.05375665701877552,0.050476389955990575,0.04739233888978078,0.04449323545417161,0.04176840260586734,0.03920773034683789,0.036801651578276307,0.034541118221875555,0.03241757772221532,0.03042295002432671,0.028549605103036946,0.026790341105274562,0.025138363153021093,0.023587262842768242,0.022130998467092544,0.020763875975101653,0.019480530680898278,0.018275909722715422,0.017145255269879422,0.016084088470153635,0.015088194126174015,0.014153606086547033,0.013276593334619502,0.012453646755933745,0.01168146656378144,0.010956950361133533,0.010277181816358505,0.009639419929637905,0.009041088866659885,0.008479768336126181,0.007953184487675458,0.0074592013070977625,0.006995812486051856,0.006561133743990144,0.006153395580522192,0.005770936437060614,0.00541219624725553,0.00507571035640364,0.0047601037907423205,0.00446408585826763,0.004186445063451005,0.003926044318976585,0.003681816438350527,0.003452759893960655,0.00323793482588397,0.0030364592874383423,0.0028475057141397198,0.002670297603420302,0.0025041063930617558,0.002348248526952812,0.002202082697345231,0.00206500725337877,0.0019364577661715732,0.001815904741311103,0.0017028514700812014,0.0015968320112278445,0.0014974092955390983,0.0014041733459297934,0.0013167396061577463,0.0012347473716578516,0.001157858316390703,0.0010857551099228147,0.0010181401193036788,0.000954734190625306,0.000895275505438553,0.0008395185074940859,0.0007872328955313979,0.0007382026781053153,0.0006922252866650158,0.0006491107433419518,0.0006086808800898069,0.0005707686060512085,0.0005352172201884553,0.000501879766407809,0.00047061842856810365,0.0004413039629240778,0.00041381516570448973,0.00038803837366274685,0.0003638669955674523,0.00034120107273083455,0.0003199468667778316,0.00030001647298405487,0.00028132745759368305,0.00026380251764512863,0.0002473691619064855,0.00023195941161890943,0.00021750951982202338,0.00020395970810938024,0.00019125391973928707,0.00017933958807714312,0.00016816741943781466,0.0001576911894132227,0.00014786755186846356,0.0001386558598048815,0.00013001799736933606,0.00012191822230245286,0.0001143230181879229,0.00010720095589400458,0.00010052256363102252,0.00009426020509173405,0.00008838796517784964,0.00008288154283087046,0.0000777181505371427,0.00007287642008324546,0.00006833631417824115,0.0000640790435753047,0.000060086989353669296,0.000056343630036481684,0.000052833473246804985,0.00004954199161821826,0.00004645556269378126,0.00004356141256933732,0.00004084756304334469,0.00003830278205874116,0.000035916537230340495,0.00003367895226591422,0.00003158076610065841,0.000029613294575847604,0.000027768394506688665,0.00002603842998460948,0.000024416240779645548,0.00002289511271036382,0.000021468749859865355,0.00002013124852062731,0.0000188770727647114,0.000017701031530981126,0.000016598257146727136,0.000015564185179339773,0.000014594535547196585,0.00001368529480605396,0.00001283269954099886,0.000012033220788021382,0.000011283549431029272,0.000010580582503694203,9.921410352164983e-6,9.303304585595029e-6,8.723706790059182e-6,8.180217937026057e-6,7.670588453079219e-6,7.192708912251433e-6,6.744601301900133e-6,6.324410839031458e-6,5.93039829110964e-6,5.560932778037042e-6,5.214485024440663e-6,4.889621024739554e-6,4.584996113221607e-6,4.2993493949428085e-6,4.0314985290113015e-6,3.7803348338361076e-6,3.5448186974651463e-6,3.3239752756930585e-6,3.116890457954824e-6,2.922707080799114e-6,2.740621383834352e-6,2.5698796786155498e-6,2.4097752331364575e-6,2.2596453439494013e-6,2.1188685945805474e-6,1.9868622822549753e-6,1.8630800064922681e-6,1.747009408026301e-6,1.6381700480572192e-6,1.5361114178435997e-6,1.4404110757482158e-6,1.3506728990808625e-6,1.2665254434107709e-6,1.187620405351808e-6,1.1136311799386789e-6,1.0442515105957284e-6,9.791942210402027e-7,9.181900255672559e-7,8.609864143860335e-7,8.073466106761629e-7,7.570485871521981e-7,7.098841503516695e-7,6.656580762154363e-7,6.241873038437262e-7,5.853001774358546e-7,5.488357344152206e-7,5.146430408498048e-7,4.825805659525173e-7,4.5251559588344037e-7,4.243236855216992e-7,3.978881426558445e-7,3.7309954525888145e-7,3.4985528740705263e-7,3.280591565069102e-7,3.0762093339298247e-7,2.88456020181016e-7,2.704850887713661e-7,2.536337537772937e-7,2.378322638829644e-7,2.2301521362955157e-7,2.091212716326396e-7,1.9609292789546373e-7,1.8387625577709343e-7,1.724206872832923e-7,1.6167880523276779e-7,1.5160614741382972e-7,1.421610202889667e-7,1.33304328242545e-7,1.249994119323361e-7,1.1721189574487312e-7,1.0990954479872528e-7,1.0306213327204716e-7,9.664131828124312e-8,9.062052330754966e-8],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('71f5d74c-6c09-42f1-bf07-954fc2cce2f5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(X, model['W1'], model['W2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkJWUa7ORtV",
        "outputId": "f3dcb71a-e8c0-4f7d-e5a2-841d711a4d01"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.7999999093794767)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}